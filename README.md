# ETL Pipeline Project Using Snowflake, dbt, and Airflow

## Introduction

This project demonstrates an ETL pipeline using Snowflake, dbt, and Apache Airflow to process mock data.

## Technologies Used

- **Snowflake**: Cloud-based data warehousing.
- **dbt**: Data transformation.
- **Airflow**: Workflow orchestration.

## Architecture

1. **Extract**: Pull mock data into Snowflake.
2. **Transform**: Use dbt to clean and process data.
3. **Load**: Store the transformed data back into Snowflake.

## Setup Instructions

Setup instructions go here whenever I get to finishing them!

## Project Structure



## Contributing

Contributions are welcome! Please fork the repository and submit a pull request.

## License

This project is licensed under the MIT License.
